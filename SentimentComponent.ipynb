{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run StoreTweetsBackend.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def removePunc(text):\n",
    "#     return [char for char in text if char not in punctuations]\n",
    "q={ \"dateRetrieved\": { \"$gt\": datetime(1000,1,30),\"$lt\": datetime(2023,1,30) },'tweetText':{ \"$exists\": True } }\n",
    "# { \"tweetText\":{\"$regex\" : \".*COPY AND .*\"}  }\n",
    "# { birth: { $gt: new Date('1920-01-01') },death: { $exists: false }}\n",
    "tweets=getQueryFromMongoDB(\"Unprocessed\",query=q,fields={\"_id\": 1, \"tweetText\": 1 }).sort_values('_id')\n",
    "sentiment140Value=getQueryFromMongoDB(\"sentiment140\").sort_values('_id')\n",
    "scoretext=sentiment140Value[['SentimentScore','tweetText']].sort_values('SentimentScore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(tweets.size,sentiment140Value.size)\n",
    "# scoretext.groupby('SentimentScore').describe()\n",
    "# scoretext.groupby(['length','SentimentScore']).describe()\n",
    "# scoretext.groupby('length').describe()\n",
    "#  scoretext[scoretext['length'] == 150]\n",
    "# sentiment140Value\n",
    "# tweets\n",
    "# scoretext['length',\"SentimentScore\"].plot(bins=20, kind='hist') \n",
    "# plt.plot(scoretext['length'],scoretext[\"SentimentScore\"])\n",
    "# scoretext.hist(column='length', by='SentimentScore', bins=50,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoretext['hasPunc'] = scoretext['tweetText'].apply(countPunctuations)\n",
    "# scoretext['hasPunc'] = scoretext['tweetText'].apply(removePunc)\n",
    "# scoretext.groupby('hasPunc').describe()\n",
    "#punctuation seems mean messages are going to be longer and more neutral when compared to no punctionation which are most likely negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_transformer = CountVectorizer(analyzer=preprocess_String).fit(scoretext['tweetText'])\n",
    "# bow_transformer.vocabulary_\n",
    "# bow4 = bow_transformer.transform(scoretext['tweetText'])\n",
    "# print(\"Vocab: \",len(bow_transformer.vocabulary_),\"\\tBOW Shape: \",bow4.shape)\n",
    "# print('Shape of Sparse Matrix: ', bow4.shape,'\\namount of Non-Zero occurences: ', bow4.nnz)\n",
    "# tfidf_transformer = TfidfTransformer().fit(bow4)\n",
    "# tfidf4 = tfidf_transformer.transform(bow4)\n",
    "# print(tfidf4)\n",
    "# print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\n",
    "# print(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])\n",
    "# messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "# print(messages_tfidf.shape)\n",
    "# sentimentModel = MultinomialNB().fit(messages_tfidf,scoretext ['SentimentScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.605939626693726\n"
     ]
    }
   ],
   "source": [
    "ssss=scoretext.sample(frac=1)\n",
    "msg_train, msg_test, label_train, label_test =train_test_split(ssss['tweetText'], ssss['SentimentScore'],shuffle=True, test_size=0.2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "def plot_ROC_NN(y_actual, y_predicted):# one vs rest roc curve\n",
    "    plt.title(\"ROC curve\")\n",
    "    y_actual[y_actual==4]=1\n",
    "    y_predicted[y_predicted==4]=1\n",
    "    plt.plot(roc_curve(y_actual,y_predicted), alpha=0.5)\n",
    "    plt.axis([0, 1, 0, 1]) \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlabel(\"False Positive\")\n",
    "    plt.ylabel(\"True Positive\")\n",
    "def plot_Matrix_NN(y_actual, y_predicted):#plots a matrix\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    matrix=confusion_matrix(y_actual,y_predicted)\n",
    "    sns.heatmap(matrix, annot=True, fmt='d',xticklabels=range(2),yticklabels=range(2))\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "\n",
    "# predictions = pipeline.predict(msg_test)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=preprocess_String)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "#     ('classifier', SVC(gamma='scale')),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "    ('classifier',  MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "start=time.time()\n",
    "pipeline.fit(msg_train,label_train)\n",
    "print(time.time()-start)\n",
    "\n",
    "# plot_ROC_NN(label_test,predictions)\n",
    "# plt.show()\n",
    "# plot_Matrix_NN(label_test,predictions)\n",
    "# print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names=BOW.get_feature_names()\n",
    "# print(\"Number of features: {}\".format(len(feature_names)))\n",
    "# print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "# print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "# print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), msg_train,label_train,cv=2)\n",
    "# print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X = vect.fit_transform(msg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect = CountVectorizer().fit(msg_train)\n",
    "X_train = vect.transform(msg_train)\n",
    "print(\"X_train:\\n{}\".format(repr(msg_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train, label_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "X_test = vect.transform(msg_test)\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, label_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.1)\n",
    "X = vect.fit_transform(msg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",max_iter=2, random_state=0)\n",
    "document_topics = lda.fit_transform(X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # for each topic (a row in the components_), sort the features (ascending).\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# get the feature names from the vectorizer:\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the 10 topics:\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda100 = LatentDirichletAllocation(n_components=100, learning_method=\"batch\",\n",
    "                                   max_iter=25, random_state=0)\n",
    "document_topics100 = lda100.fit_transform(X[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = np.array([7, 16, 24, 25, 28, 36, 37, 41, 45, 51, 53, 54, 63, 89, 97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda100.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "mglearn.tools.print_topics(topics=topics, feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by weight of \"music\" topic 45\n",
    "music = np.argsort(document_topics100[:, 45])[::-1]\n",
    "# print the five documents where the topic is most important\n",
    "for i in music[:10]:\n",
    "      # show first two sentences\n",
    "    \n",
    "    break\n",
    "music[:10]\n",
    "X[620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "topic_names = [\"{:>2} \".format(i) + \" \".join(words)\n",
    "               for i, words in enumerate(feature_names[sorting[:, :2]])]\n",
    "# two column bar chart:\n",
    "for col in [0, 1]:\n",
    "    start = col * 50\n",
    "    end = (col + 1) * 50\n",
    "    ax[col].barh(np.arange(50), np.sum(document_topics100, axis=0)[start:end])\n",
    "    ax[col].set_yticks(np.arange(50))\n",
    "    ax[col].set_yticklabels(topic_names[start:end], ha=\"left\", va=\"top\")\n",
    "    ax[col].invert_yaxis()\n",
    "    ax[col].set_xlim(0, 2000)\n",
    "    yax = ax[col].get_yaxis()\n",
    "    yax.set_tick_params(pad=130)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
